{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03033d-547e-45bf-a6d2-b89d13097318",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Helper functions for image preprocessing\n",
    "impor cv2\n",
    "import numpy as np\n",
    "\n",
    "# Helper functions\n",
    "def load_image(image_path):\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "# Function to create a saturation mask with a given threshold\n",
    "def generate_saturation_mask(image, threshold=50):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    s_channel = hsv[:, :, 1]\n",
    "    return cv2.inRange(s_channel, threshold, 255)\n",
    "\n",
    "# Function to apply a saturation mask to an image\n",
    "def apply_saturation_mask(image, saturation_mask):\n",
    "    return cv2.bitwise_and(image, image, mask=saturation_mask)\n",
    "\n",
    "# Function to create a color mask that can wrap around the hue spectrum\n",
    "def create_wrapped_color_mask(hsv_image, lower_hue, upper_hue):\n",
    "    if lower_hue > upper_hue:\n",
    "        lower_bound1 = np.array([lower_hue, 50, 50])\n",
    "        upper_bound1 = np.array([180, 255, 255])\n",
    "        lower_bound2 = np.array([0, 50, 50])\n",
    "        upper_bound2 = np.array([upper_hue, 255, 255])\n",
    "        mask1 = cv2.inRange(hsv_image, lower_bound1, upper_bound1)\n",
    "        mask2 = cv2.inRange(hsv_image, lower_bound2, upper_bound2)\n",
    "        mask = cv2.bitwise_or(mask1, mask2)\n",
    "    else:\n",
    "        lower_bound = np.array([lower_hue, 50, 50])\n",
    "        upper_bound = np.array([upper_hue, 255, 255])\n",
    "        mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "# Function to cluster hue values that are close to each other\n",
    "def cluster_hues(hues, threshold=10):\n",
    "    clusters = []\n",
    "    hues_sorted = sorted(hues)\n",
    "    cluster = [hues_sorted[0]]\n",
    "    for hue in hues_sorted[1:]:\n",
    "        if abs(hue - cluster[-1]) <= threshold:\n",
    "            cluster.append(hue)\n",
    "        else:\n",
    "            clusters.append(cluster)\n",
    "            cluster = [hue]\n",
    "    clusters.append(cluster)\n",
    "    return clusters\n",
    "\n",
    "# Function to apply median filter to a mask\n",
    "def apply_median_filter(mask):\n",
    "    return cv2.medianBlur(mask, 7)\n",
    "\n",
    "# Function to validate a mask based on the white area (non-zero pixels)\n",
    "def validate_mask(mask, area_threshold=500):\n",
    "    white_area = cv2.countNonZero(mask)\n",
    "    return white_area > area_threshold\n",
    "\n",
    "# Function to create filtered and clustered color masks based on the saturation threshold and other parameters\n",
    "def create_filtered_clustered_color_masks(image, saturation_threshold=60, hue_peak_detection_threshold=0.05, hue_threshold=10, area_threshold=500):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    saturation = hsv[:, :, 1]\n",
    "    bright_colors_mask = cv2.inRange(saturation, saturation_threshold, 255)\n",
    "    hue_channel = hsv[:, :, 0][bright_colors_mask > 0]\n",
    "    hist, _ = np.histogram(hue_channel, bins=180, range=(0, 180))\n",
    "    hist_normalized = hist / np.max(hist)\n",
    "    prominent_hues = np.where(hist_normalized > hue_peak_detection_threshold)[0]\n",
    "    hue_clusters = cluster_hues(prominent_hues, hue_threshold)\n",
    "    filtered_color_masks = {}\n",
    "    for cluster in hue_clusters:\n",
    "        lower_hue = min(cluster) - 10\n",
    "        upper_hue = max(cluster) + 10\n",
    "        mask = create_wrapped_color_mask(hsv, lower_hue, upper_hue)\n",
    "        filtered_mask = apply_median_filter(mask)\n",
    "        if validate_mask(filtered_mask, area_threshold):\n",
    "            filtered_color_masks[f'hue_{lower_hue}-{upper_hue}'] = filtered_mask\n",
    "    return filtered_color_masks\n",
    "\n",
    "def augment_saturation_mask(saturation_mask, hue_mask):\n",
    "    combined_mask = cv2.bitwise_or(saturation_mask, hue_mask)\n",
    "    return combined_mask\n",
    "\n",
    "def apply_combined_mask(image, combined_mask):\n",
    "    masked_image_with_combined_mask = cv2.bitwise_and(image, image, mask=combined_mask)\n",
    "    return masked_image_with_combined_mask\n",
    "\n",
    "def generate_gray_mask(image, lower_threshold=120, upper_threshold=150, kernel_size=5):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv_image[:,:,2], lower_threshold, upper_threshold)\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    refined_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    return refined_mask\n",
    "\n",
    "def apply_gray_mask(image, gray_mask):\n",
    "    masked_image_with_gray_mask = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(gray_mask))\n",
    "    return masked_image_with_gray_mask\n",
    "\n",
    "def calculate_writing_ratio(mask, edge_threshold=150):\n",
    "    edges = cv2.Canny(mask, edge_threshold, edge_threshold * 2)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    total_contour_area = sum(cv2.contourArea(contour) for contour in contours)\n",
    "    edge_pixels_within_contours = 0\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        edge_pixels_within_contours += np.sum(edges[y:y+h, x:x+w])\n",
    "    if total_contour_area > 0:\n",
    "        feature_proportion_within_contours = edge_pixels_within_contours / total_contour_area\n",
    "    else:\n",
    "        feature_proportion_within_contours = 0\n",
    "    return feature_proportion_within_contours\n",
    "\n",
    "def create_generalized_color_masks(image, saturation_threshold=60, hue_peak_detection_threshold=0.05):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    saturation = hsv[:, :, 1]\n",
    "    bright_colors_mask = cv2.inRange(saturation, saturation_threshold, 255)\n",
    "    hue_channel = hsv[:, :, 0][bright_colors_mask > 0]\n",
    "    hist, _ = np.histogram(hue_channel, bins=180, range=(0, 180))\n",
    "    hist_normalized = hist / np.max(hist)\n",
    "    prominent_hues = np.where(hist_normalized > hue_peak_detection_threshold)[0]\n",
    "    color_masks = {}\n",
    "    for hue in prominent_hues:\n",
    "        mask = create_wrapped_color_mask(hsv, hue - 10, hue + 10)\n",
    "        color_masks[f'hue_{hue}'] = mask\n",
    "    return color_masks\n",
    "\n",
    "def create_wrapped_color_mask(hsv_image, lower_hue, upper_hue):\n",
    "    if lower_hue > upper_hue:\n",
    "        lower_bound1 = np.array([lower_hue, 50, 50])\n",
    "        upper_bound1 = np.array([180, 255, 255])\n",
    "        lower_bound2 = np.array([0, 50, 50])\n",
    "        upper_bound2 = np.array([upper_hue, 255, 255])\n",
    "        mask1 = cv2.inRange(hsv_image, lower_bound1, upper_bound1)\n",
    "        mask2 = cv2.inRange(hsv_image, lower_bound2, upper_bound2)\n",
    "        mask = cv2.bitwise_or(mask1, mask2)\n",
    "    else:\n",
    "        lower_bound = np.array([lower_hue, 50, 50])\n",
    "        upper_bound = np.array([upper_hue, 255, 255])\n",
    "        mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "def create_writing_mask(preprocessed_image, color_masks, writing_ratio_threshold=60):\n",
    "    writing_mask = np.zeros_like(preprocessed_image[:, :, 0])\n",
    "    for hue, mask in color_masks.items():\n",
    "        writing_ratio = calculate_writing_ratio(mask)\n",
    "        if writing_ratio > writing_ratio_threshold:\n",
    "            writing_mask = cv2.bitwise_or(writing_mask, mask)\n",
    "    return writing_mask\n",
    "\n",
    "def apply_writing_mask(image, writing_mask):\n",
    "    masked_image_with_writing_mask = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(writing_mask))\n",
    "    return masked_image_with_writing_mask\n",
    "\n",
    "# New helper functions for additional preprocessing\n",
    "def remove_grayish_pixels(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_gray = np.array([0, 0, 40])  # Lower bound for gray colors\n",
    "    upper_gray = np.array([180, 65, 210])  # Upper bound for gray colors\n",
    "    gray_mask = cv2.inRange(hsv_image, lower_gray, upper_gray)\n",
    "    gray_mask_inv = cv2.bitwise_not(gray_mask)\n",
    "    gray_mask_inv_3channel = cv2.cvtColor(gray_mask_inv, cv2.COLOR_GRAY2BGR)\n",
    "    return cv2.bitwise_and(image, gray_mask_inv_3channel)\n",
    "\n",
    "def apply_thresholding(gray_image):\n",
    "    _, thresholded_image = cv2.threshold(gray_image, 15, 255, cv2.THRESH_BINARY)\n",
    "    return thresholded_image\n",
    "\n",
    "def apply_median_filter(image):\n",
    "    return cv2.medianBlur(image, 7)\n",
    "\n",
    "def mask_original_image(original_image, mask_image):\n",
    "    if len(mask_image.shape) == 2:\n",
    "        binary_mask_3channel = cv2.cvtColor(mask_image, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        binary_mask_3channel = mask_image\n",
    "    return cv2.bitwise_and(original_image, binary_mask_3channel)\n",
    "\n",
    "# Modified pipeline function including the additional preprocessing steps\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    original_image = load_image(image_path)\n",
    "\n",
    "    # Preprocess the image using saturation mask with a threshold of 50\n",
    "    saturation_mask = generate_saturation_mask(original_image, threshold=50)\n",
    "    preprocessed_image = apply_saturation_mask(original_image, saturation_mask)\n",
    "\n",
    "    # Create filtered clustered color masks instead of generalized color masks\n",
    "    color_masks = create_filtered_clustered_color_masks(original_image, saturation_threshold=50)\n",
    "\n",
    "\n",
    "    # Find a specific hue mask (e.g., hue 80) and augment the saturation mask\n",
    "    hue_80_mask = color_masks.get('hue_80', None)\n",
    "    if hue_80_mask is not None:\n",
    "        combined_mask = augment_saturation_mask(saturation_mask, hue_80_mask)\n",
    "    else:\n",
    "        combined_mask = saturation_mask\n",
    "\n",
    "    # Apply the combined mask to the image\n",
    "    image_with_combined_mask_applied = apply_combined_mask(original_image, combined_mask)\n",
    "\n",
    "    # Generate and apply gray mask to the image\n",
    "    gray_mask = generate_gray_mask(image_with_combined_mask_applied)\n",
    "    image_with_gray_mask_applied = apply_gray_mask(image_with_combined_mask_applied, gray_mask)\n",
    "\n",
    "    # Create and apply writing mask\n",
    "    writing_mask = create_writing_mask(image_with_gray_mask_applied, color_masks)\n",
    "    image_with_writing_mask_applied = apply_writing_mask(image_with_gray_mask_applied, writing_mask)\n",
    "\n",
    "    # Additional preprocessing to remove grayish pixels\n",
    "    no_gray_image = remove_grayish_pixels(image_with_writing_mask_applied)\n",
    "    gray_image = cv2.cvtColor(no_gray_image, cv2.COLOR_BGR2GRAY)\n",
    "    thresholded_image = apply_thresholding(gray_image)\n",
    "    filtered_image = apply_median_filter(thresholded_image)\n",
    "\n",
    "    # Apply the final mask to the original image\n",
    "    final_image = mask_original_image(original_image, filtered_image)\n",
    "    \n",
    "    return final_image\n",
    "\n",
    "# Example usage:\n",
    "# processed_image = process_sticky_notes_pipeline('/path/to/your/image.jpg')\n",
    "# cv2.imwrite('/path/to/save/processed_image.jpg', processed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60bd2261-041c-4bdc-979d-59ef1aa503ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Helper functions for extracting contours from preprocessed image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Helper functions for color mask creation\n",
    "def create_wrapped_color_mask(hsv_image, lower_hue, upper_hue):\n",
    "    if lower_hue > upper_hue:\n",
    "        lower_bound1 = np.array([lower_hue, 50, 50])\n",
    "        upper_bound1 = np.array([180, 255, 255])\n",
    "        lower_bound2 = np.array([0, 50, 50])\n",
    "        upper_bound2 = np.array([upper_hue, 255, 255])\n",
    "        mask1 = cv2.inRange(hsv_image, lower_bound1, upper_bound1)\n",
    "        mask2 = cv2.inRange(hsv_image, lower_bound2, upper_bound2)\n",
    "        mask = cv2.bitwise_or(mask1, mask2)\n",
    "    else:\n",
    "        lower_bound = np.array([lower_hue, 50, 50])\n",
    "        upper_bound = np.array([upper_hue, 255, 255])\n",
    "        mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "def cluster_hues(hues, threshold=10):\n",
    "    clusters = []\n",
    "    hues_sorted = sorted(hues)\n",
    "    cluster = [hues_sorted[0]]\n",
    "    for hue in hues_sorted[1:]:\n",
    "        if abs(hue - cluster[-1]) <= threshold:\n",
    "            cluster.append(hue)\n",
    "        else:\n",
    "            clusters.append(cluster)\n",
    "            cluster = [hue]\n",
    "    clusters.append(cluster)\n",
    "    return clusters\n",
    "\n",
    "def apply_median_filter(mask):\n",
    "    return cv2.medianBlur(mask, 7)\n",
    "\n",
    "def validate_mask(mask, area_threshold=500):\n",
    "    white_area = cv2.countNonZero(mask)\n",
    "    return white_area > area_threshold\n",
    "\n",
    "def create_filtered_clustered_color_masks(image, saturation_threshold=60, hue_peak_detection_threshold=0.05, hue_threshold=10, area_threshold=500):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    saturation = hsv[:, :, 1]\n",
    "    bright_colors_mask = cv2.inRange(saturation, saturation_threshold, 255)\n",
    "    hue_channel = hsv[:, :, 0][bright_colors_mask > 0]\n",
    "    hist, _ = np.histogram(hue_channel, bins=180, range=(0, 180))\n",
    "    hist_normalized = hist / np.max(hist)\n",
    "    prominent_hues = np.where(hist_normalized > hue_peak_detection_threshold)[0]\n",
    "    hue_clusters = cluster_hues(prominent_hues, hue_threshold)\n",
    "    filtered_color_masks = {}\n",
    "    for cluster in hue_clusters:\n",
    "        lower_hue = min(cluster) - 10\n",
    "        upper_hue = max(cluster) + 10\n",
    "        mask = create_wrapped_color_mask(hsv, lower_hue, upper_hue)\n",
    "        filtered_mask = apply_median_filter(mask)\n",
    "        if validate_mask(filtered_mask, area_threshold):\n",
    "            filtered_color_masks[f'hue_{lower_hue}-{upper_hue}'] = filtered_mask\n",
    "    return filtered_color_masks\n",
    "\n",
    "# Contour detection and processing functions\n",
    "def identify_valid_contours(gray_img, min_size=75):\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                            cv2.THRESH_BINARY_INV, 11, 1)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    morphed = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    valid_contours = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w >= min_size and h >= min_size:\n",
    "            valid_contours.append(contour)\n",
    "    return valid_contours\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def modified_find_most_square_contour(contours, min_size=75):\n",
    "    closest_to_square = None\n",
    "    closest_contour = None\n",
    "    min_aspect_ratio_deviation = float('inf')\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w < min_size or h < min_size:\n",
    "            continue  # Skip contours that are too small\n",
    "        aspect_ratio = float(w) / h\n",
    "        if 0.75 <= aspect_ratio <= 1.33:  # Adjusted aspect ratio check\n",
    "            deviation = abs(aspect_ratio - 1)\n",
    "            if deviation < min_aspect_ratio_deviation:\n",
    "                min_aspect_ratio_deviation = deviation\n",
    "                closest_to_square = (x, y, w, h)\n",
    "                closest_contour = contour\n",
    "    if closest_contour is not None:\n",
    "        typical_sticky_note_dimension = (w, h)\n",
    "        isolated_sticky_notes = [closest_contour]\n",
    "    else:\n",
    "        typical_sticky_note_dimension = None\n",
    "        isolated_sticky_notes = []\n",
    "    return closest_to_square, closest_contour, isolated_sticky_notes\n",
    "\n",
    "\n",
    "def is_approximately_square(contour, side_length):\n",
    "    epsilon = 0.04 * cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "    if len(approx) != 4:\n",
    "        return False\n",
    "    for i in range(4):\n",
    "        v1 = approx[i] - approx[i-1]\n",
    "        v2 = approx[i] - approx[(i+1)%4]\n",
    "        angle = np.arccos(np.dot(v1.ravel(), v2.ravel()) / (np.linalg.norm(v1) * np.linalg.norm(v2))) * (180/np.pi)\n",
    "        if not 75 < angle < 105:\n",
    "            return False\n",
    "    for i in range(4):\n",
    "        side = np.linalg.norm(approx[i] - approx[i-1])\n",
    "        if not 0.7 * side_length < side < 1.3 * side_length:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def process_remaining_sticky_notes(contours, isolated_sticky_notes):\n",
    "    complex_contours = []\n",
    "    for contour in contours:\n",
    "        if isolated_sticky_notes:  # Check if there are any isolated sticky notes\n",
    "            _, _, w, h = cv2.boundingRect(isolated_sticky_notes[0])\n",
    "            if is_approximately_square(contour, max(w, h)):\n",
    "                isolated_sticky_notes.append(contour)\n",
    "            else:\n",
    "                complex_contours.append(contour)\n",
    "        else:\n",
    "            complex_contours.append(contour)  # If no isolated sticky notes, consider contour as complex\n",
    "    return isolated_sticky_notes, complex_contours\n",
    "\n",
    "def detect_and_categorize_contours(preprocessed_img):\n",
    "    valid_contours = identify_valid_contours(preprocessed_img)\n",
    "    \n",
    "    # Find the most square contour which is assumed to be a typical sticky note\n",
    "    _, _, isolated_sticky_notes = modified_find_most_square_contour(valid_contours)\n",
    "    \n",
    "    # Process remaining contours to categorize them\n",
    "    isolated_sticky_notes, complex_contours = process_remaining_sticky_notes(valid_contours, isolated_sticky_notes)\n",
    "    \n",
    "    # Calculate average sticky note dimension\n",
    "    if isolated_sticky_notes:\n",
    "        average_dimension = np.mean([cv2.boundingRect(contour)[2:4] for contour in isolated_sticky_notes], axis=0)\n",
    "    else:\n",
    "        average_dimension = (0, 0)\n",
    "\n",
    "    return isolated_sticky_notes, complex_contours, average_dimension\n",
    "\n",
    "def calculate_angle(pt1, pt2, pt0):\n",
    "    dx1 = pt1[0][0] - pt0[0][0]\n",
    "    dy1 = pt1[0][1] - pt0[0][1]\n",
    "    dx2 = pt2[0][0] - pt0[0][0]\n",
    "    dy2 = pt2[0][1] - pt0[0][1]\n",
    "    inner_product = dx1 * dx2 + dy1 * dy2\n",
    "    len1 = np.sqrt(dx1 * dx1 + dy1 * dy1)\n",
    "    len2 = np.sqrt(dx2 * dx2 + dy2 * dy2)\n",
    "    angle = np.arccos(inner_product / (len1 * len2 + 1e-10))\n",
    "    return angle\n",
    "\n",
    "def calculate_corner_type(pt1, pt2, pt0):\n",
    "    vector_a = np.array(pt1) - np.array(pt0)\n",
    "    vector_b = np.array(pt2) - np.array(pt0)\n",
    "    angle = np.math.atan2(np.linalg.det([vector_a, vector_b]), np.dot(vector_a, vector_b))\n",
    "    return angle\n",
    "\n",
    "def refine_epsilon_light(contour, initial_epsilon_factor=0.01, refinement_factor=0.7):\n",
    "    epsilon = initial_epsilon_factor * cv2.arcLength(contour, True)\n",
    "    new_epsilon = epsilon * refinement_factor\n",
    "    new_approx = cv2.approxPolyDP(contour, new_epsilon, True)\n",
    "    return new_approx\n",
    "\n",
    "def distinguish_inside_outside_corners(contours, epsilon_factor=0.01):\n",
    "    inside_corners = []\n",
    "    outside_corners = []\n",
    "    for contour in contours:\n",
    "        approx = refine_epsilon_light(contour, epsilon_factor)\n",
    "        for i in range(len(approx)):\n",
    "            pt0 = approx[i][0]\n",
    "            pt1 = approx[(i - 1) % len(approx)][0]\n",
    "            pt2 = approx[(i + 1) % len(approx)][0]\n",
    "            angle = calculate_corner_type(pt1, pt2, pt0)\n",
    "            if angle < 0:\n",
    "                inside_corners.append(pt0)\n",
    "            else:\n",
    "                outside_corners.append(pt0)\n",
    "    return inside_corners, outside_corners\n",
    "\n",
    "def traverse_contour_and_list_corners(start_corner, all_corners, all_contours):\n",
    "    ordered_corners = []\n",
    "    for contour in all_contours:\n",
    "        try:\n",
    "            start_index = next(i for i, c in enumerate(contour) if (c[0] == start_corner).all())\n",
    "            contour_sequence = np.roll(contour, -start_index, axis=0)\n",
    "            for point in contour_sequence:\n",
    "                point = point[0]\n",
    "                for original_corner, designation in all_corners:\n",
    "                    if (point == original_corner).all():\n",
    "                        ordered_corners.append((point, designation))\n",
    "                        break\n",
    "            if len(ordered_corners) > 1 and (ordered_corners[-1][0] == start_corner).all():\n",
    "                return ordered_corners[:-1]\n",
    "        except StopIteration:\n",
    "            continue\n",
    "    return ordered_corners\n",
    "\n",
    "def generate_corner_triplets(ordered_corners):\n",
    "    triplets = []\n",
    "    length = len(ordered_corners)\n",
    "    for i in range(length):\n",
    "        corner1 = ordered_corners[i]\n",
    "        corner2 = ordered_corners[(i + 1) % length]\n",
    "        corner3 = ordered_corners[(i + 2) % length]\n",
    "        if corner1[1] == 'outside' and corner2[1] == 'outside' and corner3[1] == 'outside':\n",
    "            triplets.append((corner1[0], corner2[0], corner3[0]))\n",
    "    return triplets\n",
    "\n",
    "def verify_corner_triplets_with_tolerance(triplets, avg_sticky_note_dimension, tolerance=0.30):\n",
    "    verified_triplets = []\n",
    "    avg_note_size = np.mean(avg_sticky_note_dimension)\n",
    "    for triplet in triplets:\n",
    "        couched_corner = triplet[1]\n",
    "        other_corners = [triplet[0], triplet[2]]\n",
    "        distances = [np.linalg.norm(np.array(couched_corner) - np.array(corner)) for corner in other_corners]\n",
    "        within_tolerance = all(avg_note_size * (1 - tolerance) <= d <= avg_note_size * (1 + tolerance) for d in distances)\n",
    "        if within_tolerance:\n",
    "            verified_triplets.append((triplet, within_tolerance))\n",
    "    return verified_triplets\n",
    "\n",
    "def create_new_contours_from_triplets(triplets):\n",
    "    new_contours = []\n",
    "    for triplet in triplets:\n",
    "        couched_corner = triplet[1]\n",
    "        outer_corners = [triplet[0], triplet[2]]\n",
    "        perp_points = [calculate_perpendicular_point(couched_corner, corner) for corner in outer_corners]\n",
    "        intersection_point = find_intersection((outer_corners[0], perp_points[0]), (outer_corners[1], perp_points[1]))\n",
    "        new_contour = [couched_corner, outer_corners[0], intersection_point, outer_corners[1]]\n",
    "        new_contours.append(new_contour)\n",
    "    return new_contours\n",
    "\n",
    "def calculate_perpendicular_point(corner1, corner2):\n",
    "    dx = corner2[0] - corner1[0]\n",
    "    dy = corner2[1] - corner1[1]\n",
    "    length = np.sqrt(dx**2 + dy**2)\n",
    "    perp_x = corner2[0] - dy * (length / np.sqrt(dx**2 + dy**2))\n",
    "    perp_y = corner2[1] + dx * (length / np.sqrt(dx**2 + dy**2))\n",
    "    return int(perp_x), int(perp_y)\n",
    "\n",
    "def find_intersection(line1, line2):\n",
    "    x1, y1, x2, y2 = line1[0][0], line1[0][1], line1[1][0], line1[1][1]\n",
    "    x3, y3, x4, y4 = line2[0][0], line2[0][1], line2[1][0], line2[1][1]\n",
    "    denom = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)\n",
    "    if denom == 0:\n",
    "        return None\n",
    "    intersect_x = ((x1 * y2 - y1 * x2) * (x3 - x4) - (x1 - x2) * (x3 * y4 - y3 * x4)) / denom\n",
    "    intersect_y = ((x1 * y2 - y1 * x2) * (y3 - y4) - (y1 - y2) * (x3 * y4 - y3 * x4)) / denom\n",
    "    return int(intersect_x), int(intersect_y)\n",
    "\n",
    "def exclude_enclosed_corners(all_corners, identified_contours):\n",
    "    def reformat_point_for_cv(point):\n",
    "        return (int(point[0]), int(point[1]))\n",
    "\n",
    "    excluded_corners = []\n",
    "    for corner in all_corners:\n",
    "        is_enclosed = False\n",
    "        corner_formatted = reformat_point_for_cv(corner)\n",
    "        for sticky_note_contour in identified_contours:\n",
    "            if cv2.pointPolygonTest(sticky_note_contour, corner_formatted, False) >= 0:\n",
    "                is_enclosed = True\n",
    "                break\n",
    "        if not is_enclosed:\n",
    "            excluded_corners.append(corner)\n",
    "    return excluded_corners\n",
    "\n",
    "def find_bounding_box(corners):\n",
    "    x_coords = [pt[0] for pt in corners]\n",
    "    y_coords = [pt[1] for pt in corners]\n",
    "    return min(x_coords), min(y_coords), max(x_coords), max(y_coords)\n",
    "\n",
    "def calculate_contour_area_within_box(contour, box, image_shape):\n",
    "    mask = np.zeros(image_shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    return np.sum(mask[y_min:y_max, x_min:x_max]) // 255\n",
    "\n",
    "def center_sticky_note_in_box(box, sticky_note_size):\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    box_center = ((x_min + x_max) // 2, (y_min + y_max) // 2)\n",
    "    half_size = sticky_note_size // 2\n",
    "    return [(box_center[0] - half_size, box_center[1] - half_size), \n",
    "            (box_center[0] + half_size, box_center[1] - half_size),\n",
    "            (box_center[0] + half_size, box_center[1] + half_size), \n",
    "            (box_center[0] - half_size, box_center[1] + half_size)]\n",
    "\n",
    "def sticky_note_detection_pipeline(complex_contour, inside_corners, outside_corners, identified_sticky_notes, image_shape, avg_sticky_note_side_length=186):\n",
    "    # Combining inside and outside corners\n",
    "    all_corners = inside_corners + outside_corners\n",
    "    excluded_corners = exclude_enclosed_corners(all_corners, identified_sticky_notes)\n",
    "\n",
    "    potential_sticky_notes = []\n",
    "    bounding_box = find_bounding_box(excluded_corners)\n",
    "\n",
    "    # Check if each of the bounding box dimensions is at least 75% of the average sticky note length\n",
    "    bounding_box_width = bounding_box[2] - bounding_box[0]\n",
    "    bounding_box_height = bounding_box[3] - bounding_box[1]\n",
    "    if bounding_box_width >= avg_sticky_note_side_length * 0.75 and bounding_box_height >= avg_sticky_note_side_length * 0.75:\n",
    "        # Create a centered sticky note contour\n",
    "        potential_sticky_note_contour = center_sticky_note_in_box(bounding_box, avg_sticky_note_side_length)\n",
    "        potential_sticky_note_contour = np.array(potential_sticky_note_contour, dtype=np.int32).reshape(-1, 1, 2)\n",
    "        potential_sticky_notes.append(potential_sticky_note_contour)\n",
    "\n",
    "    return potential_sticky_notes\n",
    "\n",
    "def process_complex_contours(complex_contours, image_shape, avg_sticky_note_dimension=(186, 186), tolerance=0.30):\n",
    "    all_sticky_notes = []\n",
    "\n",
    "    for contour in complex_contours:\n",
    "        # First pass to find inside and outside corners and create the initial sticky note contours\n",
    "        inside_corners, outside_corners = distinguish_inside_outside_corners([contour])\n",
    "        combined_corners = [(corner, 'inside') for corner in inside_corners] + \\\n",
    "                           [(corner, 'outside') for corner in outside_corners]\n",
    "\n",
    "        if combined_corners:\n",
    "            # Traverse the contour and list corners to get them in order\n",
    "            start_corner = combined_corners[0][0]\n",
    "            ordered_corners = traverse_contour_and_list_corners(start_corner, combined_corners, [contour])\n",
    "            # Generate corner triplets from the ordered corners\n",
    "            corner_triplets = generate_corner_triplets(ordered_corners)\n",
    "            # Verify the corner triplets with the given tolerance\n",
    "            verified_triplets = verify_corner_triplets_with_tolerance(corner_triplets, avg_sticky_note_dimension, tolerance)\n",
    "            # Create new contours from the verified triplets\n",
    "            new_contours = create_new_contours_from_triplets([triplet for triplet, verified in verified_triplets if verified])\n",
    "            # Extend the sticky notes with new contours\n",
    "            sticky_notes = [np.array(contour, dtype=np.int32).reshape((-1, 1, 2)) for contour in new_contours]\n",
    "            all_sticky_notes.extend(sticky_notes)\n",
    "\n",
    "        # Additional detection phase within complex contours\n",
    "        additional_sticky_notes = sticky_note_detection_pipeline(contour, inside_corners, outside_corners, all_sticky_notes, image_shape, avg_sticky_note_dimension[0])\n",
    "        # Add any new detected sticky notes to the list\n",
    "        all_sticky_notes.extend(additional_sticky_notes)\n",
    "\n",
    "    return all_sticky_notes\n",
    "\n",
    "def extract_contours(image):\n",
    "    filtered_color_masks = create_filtered_clustered_color_masks(image)\n",
    "    all_isolated_sticky_notes = []\n",
    "    all_complex_contours = []\n",
    "    dimensions_list = []\n",
    "\n",
    "    # Process each color mask\n",
    "    for color_range, mask in filtered_color_masks.items():\n",
    "        # Ensure the mask is in the correct format for contour detection (single-channel)\n",
    "        if len(mask.shape) == 3 and mask.shape[2] == 3:  # If the mask is not a single channel, convert it\n",
    "            gray_mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray_mask = mask\n",
    "\n",
    "        # Corrected unpacking here\n",
    "        isolated_sticky_notes, complex_contours, average_dimension = detect_and_categorize_contours(gray_mask)\n",
    "        all_isolated_sticky_notes.extend(isolated_sticky_notes)\n",
    "        all_complex_contours.extend(complex_contours)\n",
    "        if average_dimension is not None:  # Corrected comparison here\n",
    "            dimensions_list.append(average_dimension)\n",
    "\n",
    "\n",
    "    # Process complex contours to identify additional sticky notes\n",
    "    image_shape = image.shape[:2]\n",
    "    additional_sticky_notes = process_complex_contours(all_complex_contours, image_shape, average_dimension)\n",
    "\n",
    "    # Combine isolated sticky notes with those extracted from complex contours\n",
    "    all_sticky_notes = all_isolated_sticky_notes + additional_sticky_notes\n",
    "\n",
    "    return all_sticky_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea0a891-b321-42f8-bed2-16af46581f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for extracting images from note contours\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from matplotlib.colors import rgb2hex\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    widthA = np.linalg.norm(br - bl)\n",
    "    widthB = np.linalg.norm(tr - tl)\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    heightA = np.linalg.norm(tr - br)\n",
    "    heightB = np.linalg.norm(tl - bl)\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]\n",
    "    ], dtype=\"float32\")\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    return cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "def get_average_color(image):\n",
    "    avg_color_per_row = np.mean(image, axis=0)\n",
    "    avg_color = np.mean(avg_color_per_row, axis=0)\n",
    "    return avg_color\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
    "\n",
    "def find_contour_center(contour):\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        cX, cY = contour[0][0]\n",
    "    return cX, cY\n",
    "\n",
    "def process_image_into_notes(image_path, contours):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Extracting the base name of the image file (e.g., 'IMG_0220' from 'IMG_0220.jpg')\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    \n",
    "    # Constructing the zip file name with the image name prefix and '_notes.zip' suffix\n",
    "    zip_filename = os.path.join(os.getcwd(), f\"{base_name}_notes.zip\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "        for i, c in enumerate(contours):\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            processed_contour = np.int0(box)\n",
    "            angle = rect[2]\n",
    "            if angle < -45:\n",
    "                angle += 90\n",
    "\n",
    "            warped_image = four_point_transform(image, processed_contour.reshape(4, 2))\n",
    "            avg_color = get_average_color(warped_image)\n",
    "            hex_color = rgb_to_hex(avg_color)\n",
    "            center_x, center_y = find_contour_center(c)\n",
    "\n",
    "            # Encoding the image and writing directly to the zip file\n",
    "            _, buffer = cv2.imencode('.png', warped_image)\n",
    "            image_name = f\"{base_name}_image-{i}_{center_x}_{center_y}_{int(angle)}_{hex_color.replace('#', '')}.png\"\n",
    "            zipf.writestr(image_name, buffer.tobytes())\n",
    "\n",
    "    return zip_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4710e-9dfb-405f-9c33-f143f43aa6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main workchain function for processing an image into sticky notes\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Importing functions from the helper files using the convention\n",
    "import HELPER_preprocess_image as preproc\n",
    "import HELPER_extract_contours as extract\n",
    "import HELPER_extract_images_from_note_contours as process_notes\n",
    "\n",
    "# Function to process the entire poster image and extract notes\n",
    "def process_sticky_note_poster(image_path):\n",
    "    final_preprocessed_image = preproc.preprocess_image(image_path)\n",
    "    sticky_note_contours = extract.extract_contours(final_preprocessed_image)\n",
    "    notes_zip_file = process_notes.process_image_into_notes(image_path, sticky_note_contours)\n",
    "    return notes_zip_file\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if an image path was provided\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python process_poster.py <image_path>\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    image_path = sys.argv[1]\n",
    "    \n",
    "    # Check if the provided path is valid\n",
    "    if not os.path.isfile(image_path):\n",
    "        print(f\"The provided image path does not exist: {image_path}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Process the image and get the path to the saved zip file\n",
    "    zip_file_path = process_sticky_note_poster(image_path)\n",
    "    \n",
    "    # Save the zip file in the current working directory\n",
    "    local_zip_path = os.path.join(os.getcwd(), os.path.basename(zip_file_path))\n",
    "    os.rename(zip_file_path, local_zip_path)\n",
    "    \n",
    "    print(f\"Process complete. Zip file saved to: {local_zip_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605105cf-545f-4653-8f81-d14c4087c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function for generating a Miro board from a set of images\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Constants for sticky note dimensions\n",
    "NOTE_WIDTH = 372  # Width of the sticky note\n",
    "NOTE_HEIGHT = 372  # Height of the sticky note\n",
    "\n",
    "# Function to clear the console\n",
    "def clear():\n",
    "    if sys.platform == 'darwin':\n",
    "        os.system('clear')\n",
    "    else:\n",
    "        os.system('cls')\n",
    "\n",
    "# Function to read Miro API Key, Client ID, Client Secret, and Board ID from a text file\n",
    "def read_miro_credentials(file_path='miro_api_key.txt'):\n",
    "    credentials = {}\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                key, value = line.strip().split(': ')\n",
    "                credentials[key] = value\n",
    "        return credentials\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{file_path}' not found.\")\n",
    "        sys.exit(1)\n",
    "    except ValueError:\n",
    "        print(f\"Error: Invalid format in '{file_path}'.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# Helper function to convert hex to RGB\n",
    "def hex_to_rgb(hex_code):\n",
    "    hex_code = hex_code.lstrip('#')\n",
    "    return tuple(int(hex_code[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "# Function to map hex codes to Miro's predefined colors\n",
    "def map_hex_to_miro_color(hex_code):\n",
    "    miro_colors = {\n",
    "        \"gray\": \"#808080\",\n",
    "        \"light_yellow\": \"#ffff99\",\n",
    "        \"yellow\": \"#ffeb3b\",\n",
    "        \"orange\": \"#ff9800\",\n",
    "        \"light_green\": \"#ccff90\",\n",
    "        \"green\": \"#4caf50\",\n",
    "        \"dark_green\": \"#388e3c\",\n",
    "        \"cyan\": \"#00bcd4\",\n",
    "        \"light_pink\": \"#f8bbd0\",\n",
    "        \"pink\": \"#e91e63\",\n",
    "        \"violet\": \"#9c27b0\",\n",
    "        \"red\": \"#f44336\",\n",
    "        \"light_blue\": \"#81d4fa\",\n",
    "        \"blue\": \"#2196f3\",\n",
    "        \"dark_blue\": \"#1565c0\",\n",
    "        \"black\": \"#000000\"\n",
    "    }\n",
    "\n",
    "    target_rgb = hex_to_rgb(hex_code)\n",
    "    min_distance = float('inf')\n",
    "    closest_color_name = \"light_yellow\"  # Default color\n",
    "\n",
    "    for color_name, miro_hex in miro_colors.items():\n",
    "        miro_rgb = hex_to_rgb(miro_hex)\n",
    "        distance = sum((src - dst) ** 2 for src, dst in zip(target_rgb, miro_rgb))\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_color_name = color_name\n",
    "\n",
    "    return closest_color_name\n",
    "\n",
    "def create_poster_frame(board_id, width, height, access_token):\n",
    "    url = f\"https://api.miro.com/v2/boards/{board_id}/frames\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"data\": {\n",
    "            \"title\": \"Poster Frame\"\n",
    "        },\n",
    "        \"geometry\": {\n",
    "            \"height\": height,\n",
    "            \"width\": width\n",
    "        },\n",
    "        \"position\": {\n",
    "            \"x\": 0,\n",
    "            \"y\": 0\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    frame_info = response.json()\n",
    "    print(\"Poster Frame Creation Response:\", frame_info)\n",
    "\n",
    "    # Check if the response contains an 'id' before returning it\n",
    "    if 'id' in frame_info:\n",
    "        return frame_info['id']\n",
    "    else:\n",
    "        print(\"Error creating poster frame:\", frame_info)\n",
    "        sys.exit(1)\n",
    "\n",
    "# Function to scale coordinates and adjust for note size and poster position\n",
    "def scale_coordinates(x, y, image_width, image_height, frame_width, frame_height):\n",
    "    # Scale the coordinates from the image to the frame size\n",
    "    scaled_x = (x / image_width) * frame_width\n",
    "    scaled_y = (y / image_height) * frame_height\n",
    "\n",
    "    # Adjust coordinates relative to the frame's top-left corner\n",
    "    # Assuming the frame is centered on the board, we need to offset the coordinates\n",
    "    offset_x = frame_width / 2\n",
    "    offset_y = frame_height / 2\n",
    "    adjusted_x = scaled_x - offset_x\n",
    "    adjusted_y = scaled_y - offset_y\n",
    "\n",
    "    return adjusted_x, adjusted_y\n",
    "\n",
    "# Function to calculate the relative position within the original image and\n",
    "# transform the position to the frame's coordinate system on the Miro board\n",
    "\n",
    "def transform_to_frame_coordinates(x, y, csv_width, csv_height, frame_width, frame_height, note_width, note_height):\n",
    "    # Translate CSV coordinates from top-left origin to center origin\n",
    "    translated_x = x - (csv_width / 2)\n",
    "    translated_y = (csv_height / 2) - y\n",
    "\n",
    "    # Adjust the translated coordinates to be relative to the top-left of the frame\n",
    "    adjusted_x = translated_x + (frame_width / 2)\n",
    "    adjusted_y = (frame_height / 2) - translated_y\n",
    "\n",
    "    # Adjust for the sticky note size\n",
    "    adjusted_x -= note_width / 2\n",
    "    adjusted_y -= note_height / 2\n",
    "\n",
    "    # Ensure the sticky note is within the frame boundaries\n",
    "    adjusted_x = max(min(adjusted_x, frame_width - note_width), 0)\n",
    "    adjusted_y = max(min(adjusted_y, frame_height - note_height), 0)\n",
    "\n",
    "    return adjusted_x, adjusted_y\n",
    "\n",
    "\n",
    "# Modify the create_square_sticky_note function to accept the frame dimensions and use the new transform function\n",
    "\n",
    "def create_square_sticky_note(board_id, text, x, y, hex_code, access_token, include_color, parent_id):\n",
    "    url = f\"https://api.miro.com/v2/boards/{board_id}/sticky_notes\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Determine the shape and set the geometry accordingly\n",
    "    if NOTE_WIDTH == NOTE_HEIGHT:\n",
    "        # If the note is square, only pass the height\n",
    "        shape = \"square\"\n",
    "        geometry = {\"height\": NOTE_HEIGHT}\n",
    "    else:\n",
    "        # If the note is rectangular, pass both width and height\n",
    "        shape = \"rectangle\"\n",
    "        geometry = {\"width\": NOTE_WIDTH, \"height\": NOTE_HEIGHT}\n",
    "\n",
    "    payload = {\n",
    "        \"data\": {\n",
    "            \"content\": text,\n",
    "            \"shape\": shape\n",
    "        },\n",
    "        \"geometry\": geometry,\n",
    "        \"parent\": {\n",
    "            \"id\": parent_id\n",
    "        },\n",
    "        \"position\": {\n",
    "            \"x\": x,\n",
    "            \"y\": y\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Include color if specified\n",
    "    if include_color:\n",
    "        fillColor = map_hex_to_miro_color(hex_code)\n",
    "        payload[\"style\"] = {\"fillColor\": fillColor}\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    print(\"Sticky Note Creation Response:\", response.json())\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# Main function to process CSV and create notes on Miro\n",
    "def process_csv_and_create_notes(csv_filename, board_id, access_token, include_color, parent_id):\n",
    "    # Open the CSV file\n",
    "    with open(csv_filename, mode='r', encoding='utf-8-sig') as file:\n",
    "        # Initialize the CSV reader\n",
    "        reader = csv.DictReader(file)\n",
    "\n",
    "        # Iterate over each row in the CSV\n",
    "        for row in reader:\n",
    "            # Convert CSV coordinates to Miro frame coordinates\n",
    "            x, y = transform_to_frame_coordinates(\n",
    "                int(row['center_x']), int(row['center_y']),\n",
    "                csv_width=3024, csv_height=4032,  # Original image size\n",
    "                frame_width=3024, frame_height=4032,  # Frame size\n",
    "                note_width=NOTE_WIDTH, note_height=NOTE_HEIGHT  # Sticky note dimensions\n",
    "            )\n",
    "\n",
    "            # Log the transformed coordinates for debugging\n",
    "            print(f\"Transformed coordinates for {row['extracted_text']}: x={x}, y={y}\")\n",
    "\n",
    "            # Create the sticky note\n",
    "            create_square_sticky_note(\n",
    "                board_id, row['extracted_text'], \n",
    "                x, y, row['hex_code'], \n",
    "                access_token, \n",
    "                include_color, \n",
    "                parent_id  # The ID of the poster frame\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "# Entry point for the script\n",
    "if __name__ == '__main__':\n",
    "    # Default poster dimensions\n",
    "    poster_width = 3024\n",
    "    poster_height = 4032\n",
    "\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python script.py <csv_filename> [--no-color] [poster-x-dimension] [poster-y-dimension]\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    csv_filename = sys.argv[1]\n",
    "    include_color = '--no-color' not in sys.argv\n",
    "\n",
    "    # Check for poster dimensions in arguments\n",
    "    if len(sys.argv) > 3:\n",
    "        poster_width = int(sys.argv[3])\n",
    "    if len(sys.argv) > 4:\n",
    "        poster_height = int(sys.argv[4])\n",
    "\n",
    "    credentials = read_miro_credentials()\n",
    "    access_token = credentials.get('access_token', '')\n",
    "    board_id = credentials.get('board_id', '')\n",
    "    if not access_token or not board_id:\n",
    "        print(\"Error: Access token or board ID not found in 'miro_api_key.txt'.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    clear()\n",
    "    print(\"Creating poster frame on Miro board...\")\n",
    "    poster_id = create_poster_frame(board_id, poster_width, poster_height, access_token)\n",
    "\n",
    "    print(\"Processing CSV and creating square notes on Miro board...\")\n",
    "    process_csv_and_create_notes(csv_filename, board_id, access_token, include_color, poster_id)\n",
    "    print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sticky-notes",
   "language": "python",
   "name": "sticky-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
